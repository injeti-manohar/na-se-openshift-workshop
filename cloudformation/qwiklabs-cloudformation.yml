---

AWSTemplateFormatVersion: 2010-09-09
Description: Cloudformation for OpenShift Admin Test Drive

Parameters:

  PublicHostedZone:
    Type: String
    Default: "aws.testdrive.openshift.com"
    ConstraintDescription: DNS zone for Instances and OpenShift

  InfraInstanceType:
    Type: String
    Default: t2.large
    AllowedValues:
      - t2.large
      - m4.large
      - m4.xlarge
    ConstraintDescription: Must be a valid EC2 instance type.

  WorkerInstanceType:
    Type: String
    Default: t2.large
    AllowedValues:
      - t2.large
      - m4.large
      - m4.xlarge

  CNSInstanceType:
    Type: String
    Default: t2.medium
    AllowedValues:
      - t2.medium
      - t2.large

  MasterInstanceType:
    Type: String
    Default: t2.large
    AllowedValues:
      - t2.large
      - t2.xlarge
      - m4.large
      - m4.xlarge
    ConstraintDescription: Must be a valid EC2 instance type.

  IdmInstanceType:
    Type: String
    Default: t2.medium
    AllowedValues:
      - t2.medium
    ConstraintDescription: Must be a valid EC2 instance type.

  SupportInstanceType:
    Type: String
    Default: t2.large
    AllowedValues:
      - t2.large
      - m4.large
    ConstraintDescription: Must be a valid EC2 instance type.

  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Default: generic-qwiklab
    ConstraintDescription: Must be the name of an existing EC2 key pair.

  QwiklabId:
    Type: String
    Default: na-se, combined-workshop
    ConstraintDescription: Must be the name of a branch in the GitHub repository we are using in various cloud-init modules.

Mappings:
  AWSRegion2AMI:
    us-east-1:
      ami: ami-0f6b786a45ce5229a
    us-east-2:
      ami: NOT_SUPPORTED
    us-west-1:
      ami: NOT_SUPPORTED
    us-west-2:
      ami: ami-0e1c2f316bc086eab
    eu-west-1:
      ami: ami-0f687991e09a8c4bc
    eu-central-1:
      ami: ami-0ef64a7e8a10fa056
    ap-northeast-1:
      ami: NOT_SUPPORTED
    ap-northeast-2:
      ami: NOT_SUPPORTED
    ap-southeast-1:
      ami: ami-09f821e7bdf3d917e
    ap-southeast-2:
      ami: NOT_SUPPORTED
    sa-east-1:
      ami: NOT_SUPPORTED

  Subnet2Cidr:
    vpc:
      cidr: 10.0.0.0/16
    public1:
      cidr: 10.0.1.0/24
    public2:
      cidr: 10.0.3.0/24
    public3:
      cidr: 10.0.4.0/24

  DNSMapping:
      us-east-1:
        domain: ec2.internal
      us-west-1:
        domain: us-west-1.compute.internal
      us-west-2:
        domain: us-west-2.compute.internal
      eu-west-1:
        domain: eu-west-1.compute.internal
      eu-central-1:
        domain: eu-central-1.compute.internal
      ap-northeast-1:
        domain: ap-northeast-1.compute.internal
      ap-northeast-2:
        domain: ap-northeast-2.compute.internal
      ap-southeast-1:
        domain: ap-southeast-1.compute.internal
      ap-southeast-2:
        domain: ap-southeast-2.compute.internal
      sa-east-1:
        domain: sa-east-1.compute.internal

Resources:

  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock:
        Fn::FindInMap:
        - Subnet2Cidr
        - vpc
        - cidr
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  DhcpOptions:
    Type: "AWS::EC2::DHCPOptions"
    Properties:
      DomainName: internal.aws.testdrive.openshift.com
      DomainNameServers:
        - AmazonProvidedDNS

  VPCDHCPOptionsAssociation:
    Type: AWS::EC2::VPCDHCPOptionsAssociation
    Properties:
      VpcId:
        Ref: VPC
      DhcpOptionsId:
        Ref: DhcpOptions

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  InternetGatewayAttachement:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId:
        Ref: VPC
      InternetGatewayId:
        Ref: InternetGateway

  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId:
        Ref: VPC
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  PublicRouteTableDefaultRoute1:
    Type: AWS::EC2::Route
    DependsOn: InternetGatewayAttachement
    Properties:
      RouteTableId:
        Ref: PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId:
        Ref: InternetGateway

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId:
        Ref: VPC
      CidrBlock:
        Fn::FindInMap:
        - Subnet2Cidr
        - public1
        - cidr
      MapPublicIpOnLaunch: 'true'
      AvailabilityZone:
        Fn::Select:
          - 0
          - Fn::GetAZs: ""
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  PublicSubnetRouteTableAssociation1:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId:
        Ref: PublicSubnet1
      RouteTableId:
        Ref: PublicRouteTable

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId:
        Ref: VPC
      CidrBlock:
        Fn::FindInMap:
        - Subnet2Cidr
        - public2
        - cidr
      MapPublicIpOnLaunch: 'true'
      AvailabilityZone:
        Fn::Select:
          - 1
          - Fn::GetAZs: ""
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  PublicSubnetRouteTableAssociation2:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId:
        Ref: PublicSubnet2
      RouteTableId:
        Ref: PublicRouteTable

  PublicSubnet3:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId:
        Ref: VPC
      CidrBlock:
        Fn::FindInMap:
        - Subnet2Cidr
        - public3
        - cidr
      MapPublicIpOnLaunch: 'true'
      AvailabilityZone:
        Fn::Select:
          - 2
          - Fn::GetAZs: ""
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  PublicSubnetRouteTableAssociation3:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId:
        Ref: PublicSubnet3
      RouteTableId:
        Ref: PublicRouteTable

  NodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId:
        Ref: VPC
      GroupDescription: Firewall definition for OpenShift Node
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 111
        ToPort: 111
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 3260
        ToPort: 3260
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 4789
        ToPort: 4789
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 3260
        ToPort: 3260
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 111
        ToPort: 111
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 24010
        ToPort: 24010
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 4789
        ToPort: 4789
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 10250
        ToPort: 10250
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 10250
        ToPort: 10250
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 2222
        ToPort: 2222
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 24007
        ToPort: 24008
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 24010
        ToPort: 24010
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 49152
        ToPort: 49664
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 5000
        ToPort: 5000
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 389
        ToPort: 389
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 88
        ToPort: 88
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 88
        ToPort: 88
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 123
        ToPort: 123
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 464
        ToPort: 464
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 464
        ToPort: 464
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 749
        ToPort: 749
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 636
        ToPort: 636
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 9100
        ToPort: 9100
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 1936
        ToPort: 1936
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 8444
        ToPort: 8444
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 8443
        ToPort: 8443
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 443
        ToPort: 443
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 8080
        ToPort: 8080
        CidrIp: 0.0.0.0/0
      - IpProtocol: icmp
        FromPort: -1
        ToPort: -1
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      SecurityGroupEgress:
      - IpProtocol: -1
        FromPort: 0
        ToPort: 65535
        CidrIp: 0.0.0.0/0

  IdmSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId:
        Ref: VPC
      GroupDescription: Firewall definition for Idm
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 389
        ToPort: 389
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 88
        ToPort: 88
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 88
        ToPort: 88
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 123
        ToPort: 123
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 464
        ToPort: 464
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 464
        ToPort: 464
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 749
        ToPort: 749
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 636
        ToPort: 636
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 443
        ToPort: 443
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: icmp
        FromPort: -1
        ToPort: -1
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      SecurityGroupEgress:
      - IpProtocol: -1
        FromPort: 0
        ToPort: 65535
        CidrIp: 0.0.0.0/0

  MasterSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId:
        Ref: VPC
      GroupDescription: Firewall definition for OpenShift Master and Heketi
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 443
        ToPort: 443
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 4789
        ToPort: 4789
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 4789
        ToPort: 4789
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 2049
        ToPort: 2049
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 8053
        ToPort: 8053
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 53
        ToPort: 53
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 53
        ToPort: 53
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: udp
        FromPort: 8053
        ToPort: 8053
        CidrIp: !FindInMap [ Subnet2Cidr, vpc, cidr ]
      - IpProtocol: tcp
        FromPort: 8080
        ToPort: 8080
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 443
        ToPort: 443
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: 0.0.0.0/0
      - IpProtocol: icmp
        FromPort: -1
        ToPort: -1
        CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
      - IpProtocol: -1
        FromPort: 0
        ToPort: 65535
        CidrIp: 0.0.0.0/0

  InternalDNS:
    Type: "AWS::Route53::HostedZone"
    DependsOn:
      - VPC
      - Master1NetworkInterface
      - InfraNode1NetworkInterface
      - IdmNode1NetworkInterface
      - SupportNodeNetworkInterface
      - WorkerNode1NetworkInterface
      - WorkerNode2NetworkInterface
      - WorkerNode3NetworkInterface
      - WorkerNode4NetworkInterface
      - WorkerNode5NetworkInterface
      - WorkerNode6NetworkInterface
    Properties:
      HostedZoneConfig:
        Comment: "Internal Hosted Zone"
      Name: internal.aws.testdrive.openshift.com
      VPCs:
      -
        VPCId: !Ref "VPC"
        VPCRegion: !Ref "AWS::Region"

  InternalRoute53Records:
    Type: AWS::Route53::RecordSetGroup
    DependsOn:
      - InternalDNS
      - Master1NetworkInterface
      - InfraNode1NetworkInterface
      - IdmNode1NetworkInterface
      - SupportNodeNetworkInterface
      - WorkerNode1NetworkInterface
      - WorkerNode2NetworkInterface
      - WorkerNode3NetworkInterface
      - WorkerNode4NetworkInterface
      - WorkerNode5NetworkInterface
      - WorkerNode6NetworkInterface
    Properties:
      HostedZoneName: !Join ['', [internal., !Ref 'PublicHostedZone', .]]
      RecordSets:
        - Name: !Join ['', [master.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt Master1NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [infra.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt InfraNode1NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [idm.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt IdmNode1NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [support.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt SupportNodeNetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [node01.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode1NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [node02.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode2NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [node03.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode3NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [node04.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode4NetworkInterface.PrimaryPrivateIpAddress


        - Name: !Join ['', [node05.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode5NetworkInterface.PrimaryPrivateIpAddress

        - Name: !Join ['', [node06.internal., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode6NetworkInterface.PrimaryPrivateIpAddress

  Route53Records:
    Type: AWS::Route53::RecordSetGroup
    DependsOn:
      - Master1
      - InfraNode1
      - IdmNode1
      - WorkerNode1
      - WorkerNode2
      - WorkerNode3
      - WorkerNode4
      - WorkerNode5
      - WorkerNode6
      - SupportNode
    Properties:
      HostedZoneName: !Join ['', [!Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
      RecordSets:
        - Name: !Join ['', [master., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt Master1.PublicIp

        - Name: !Join ['', [openshift., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt Master1.PublicIp

        - Name: !Join ['', [infra., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt InfraNode1.PublicIp

        - Name: !Join ['', ["*", .,  apps., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt InfraNode1.PublicIp

        - Name: !Join ['', [idm., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt IdmNode1.PublicIp

        - Name: !Join ['', [support., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt SupportNode.PublicIp

        - Name: !Join ['', [ssh., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt SupportNode.PublicIp

        - Name: !Join ['', [node01., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode1.PublicIp

        - Name: !Join ['', [node02., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode2.PublicIp

        - Name: !Join ['', [node03., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode3.PublicIp

        - Name: !Join ['', [node04., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode4.PublicIp

        - Name: !Join ['', [node05., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode5.PublicIp

        - Name: !Join ['', [node06., !Ref 'AWS::AccountId', ., !Ref 'PublicHostedZone', .]]
          Type: A
          TTL: '900'
          ResourceRecords:
          - !GetAtt WorkerNode6.PublicIp

  OpenShiftWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  OpenShiftWaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: SupportNode
    Properties:
      Handle: !Ref OpenShiftWaitHandle
      Timeout: '2400'

  PostDeployWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  PostDeployWaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: SupportNode
    Properties:
      Handle: !Ref PostDeployWaitHandle
      Timeout: '2400'

  Master1NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref MasterSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  Master1:
    Type: AWS::EC2::Instance
    DependsOn:
      - IdmNode1
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: MasterInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref Master1NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [master, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      BlockDeviceMappings:
      - DeviceName: /dev/sda1
        Ebs:
          VolumeSize: '10'
          VolumeType: 'gp2'
          DeleteOnTermination: 'true'
      - DeviceName: /dev/xvdb
        Ebs:
          VolumeSize: '20'
          VolumeType: 'gp2'
          DeleteOnTermination: 'true'
      - DeviceName: /dev/xvdc
        Ebs:
          VolumeSize: '10'
          VolumeType: 'gp2'
          DeleteOnTermination: 'true'
      - DeviceName: /dev/xvdd
        Ebs:
          VolumeSize: '10'
          VolumeType: 'gp2'
          DeleteOnTermination: 'true'
      UserData:
        Fn::Base64:
          !Sub
            - |
              #cloud-config

              fs_setup:
              - label: etcd_storage
                filesystem: xfs
                device: /dev/xvdd
                partition: auto

              fqdn: master.internal.${PublicHostedZone}

              chpasswd:
                list: |
                  cloud-user:${KeyName}
                expire: False

              ssh_pwauth: True

              runcmd:
              - ansible localhost -m wait_for -a "port=22 host=${IdmNode1.PrivateIp}"
              - ansible-playbook /opt/lab/helpers/fetch_idm_cert.yml
              - mkdir -p /var/lib/etcd
              - git clone -b ${RepoBranch} https://github.com/${RepoAccount}/na-se-openshift-workshop.git /opt/lab/code
              - chown -R cloud-user:cloud-user /opt/lab
              - cp /opt/lab/code/support/* /opt/lab/support/
              - chown -R cloud-user:cloud-user /opt/lab
              - systemctl start httpd

              write_files:
                - content: |
                    kind: LDAPSyncConfig
                    apiVersion: v1
                    url: ldap://idm.internal.aws.testdrive.openshift.com
                    ca: /etc/origin/master/ipa-ca.crt
                    bindDN: uid=system,cn=sysaccounts,cn=etc,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com
                    bindPassword: bindingpassword
                    rfc2307:
                      groupsQuery:
                        baseDN: cn=groups,cn=accounts,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com
                        derefAliases: never
                        filter: '(|(cn=ose-*))'
                      groupUIDAttribute: dn
                      groupNameAttributes:
                      - cn
                      groupMembershipAttributes:
                      - member
                      usersQuery:
                        baseDN: cn=users,cn=accounts,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com
                        derefAliases: never
                      userUIDAttribute: dn
                      userNameAttributes:
                      - uid
                  path: /opt/lab/support/groupsync.yaml
                  owner: cloud-user:cloud-user

                - content: |
                    {
                        "clusters": [
                            {
                                "nodes": [
                                    {
                                        "node": {
                                            "hostnames": {
                                                "manage": [
                                                    "node04.internal.${PublicHostedZone}"
                                                ],
                                                "storage": [
                                                    "${WorkerNode4.PrivateIp}"
                                                ]
                                            },
                                            "zone": 1
                                        },
                                        "devices": [
                                            "/dev/xvdd"
                                        ]
                                    },
                                    {
                                        "node": {
                                            "hostnames": {
                                                "manage": [
                                                    "node05.internal.${PublicHostedZone}"
                                                ],
                                                "storage": [
                                                    "${WorkerNode5.PrivateIp}"
                                                ]
                                            },
                                            "zone": 2
                                        },
                                        "devices": [
                                            "/dev/xvdd"
                                        ]
                                    },
                                    {
                                        "node": {
                                            "hostnames": {
                                                "manage": [
                                                    "node06.internal.${PublicHostedZone}"
                                                ],
                                                "storage": [
                                                    "${WorkerNode6.PrivateIp}"
                                                ]
                                            },
                                            "zone": 3
                                        },
                                        "devices": [
                                            "/dev/xvdd"
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                  path: /opt/lab/support/topology-new.json
                  owner: cloud-user:cloud-user

                - content: |
                    OCP_ROUTING_SUFFIX: "apps.${AWS::AccountId}.${PublicHostedZone}"
                    NODE_BRICK_DEVICE: "/dev/xvdd"
                    NODE_BRICK_DEVICE2: "/dev/xvde"
                    CNS_NAMESPACE: "storage"
                    CNS_INFRA_NAMESPACE: "infra-storage"
                    HEKETI_ADMIN_PW: "myS3cr3tpassw0rd"
                    HEKETI_ADMIN_PW_BASE64: "bXlTM2NyM3RwYXNzdzByZA=="
                    HEKETI_USER_PW: "mys3rs3cr3tpassw0rd"
                    CNS_STORAGECLASS: "glusterfs-storage"
                    CNS_BLOCK_STORAGECLASS: "glusterfs-registry-block"
                    CNS_INFRA_STORAGECLASS: "glusterfs-registry"
                    NODE4_EXTERNAL_FQDN: "node04.${AWS::AccountId}.${PublicHostedZone}"
                    NODE5_EXTERNAL_FQDN: "node05.${AWS::AccountId}.${PublicHostedZone}"
                    NODE6_EXTERNAL_FQDN: "node06.${AWS::AccountId}.${PublicHostedZone}"
                    MASTER_INTERNAL_FQDN: "master.internal.${PublicHostedZone}"
                    INFRA_INTERNAL_FQDN: "infra.internal.${PublicHostedZone}"
                    NODE1_INTERNAL_FQDN: "node01.internal.${PublicHostedZone}"
                    NODE2_INTERNAL_FQDN: "node02.internal.${PublicHostedZone}"
                    NODE3_INTERNAL_FQDN: "node03.internal.${PublicHostedZone}"
                    NODE4_INTERNAL_FQDN: "node04.internal.${PublicHostedZone}"
                    NODE5_INTERNAL_FQDN: "node05.internal.${PublicHostedZone}"
                    NODE6_INTERNAL_FQDN: "node06.internal.${PublicHostedZone}"
                    IDM_INTERNAL_FQDN: "idm.internal.${PublicHostedZone}"
                    WEB_CONSOLE_URL: "https://openshift.${AWS::AccountId}.${PublicHostedZone}/console"
                    SSH_CONSOLE_URL: "http://ssh.${AWS::AccountId}.${PublicHostedZone}:8080/ssh/host/master.internal.${PublicHostedZone}"
                    API_HEALTH_URL: "https://openshift.${AWS::AccountId}.${PublicHostedZone}/healthz/ready"
                  path: /opt/lab/environment.yml

                - content: |
                    [OSEv3:children]
                    masters
                    nodes
                    etcd
                    glusterfs
                    #scaleup_new_nodes
                    glusterfs_registry

                    [OSEv3:vars]
                    ansible_become=true
                    openshift_deployment_type=openshift-enterprise
                    openshift_disable_check=memory_availability,disk_availability,docker_storage,package_version,docker_image_availability,package_availability
                    openshift_enable_service_catalog=false
                    openshift_master_dynamic_provisioning_enabled=true
                    osm_use_cockpit=false

                    openshift_master_api_port=443
                    openshift_master_console_port=443
                    openshift_master_identity_providers=[{'name': 'idm', 'challenge': 'true', 'login': 'true', 'kind': 'LDAPPasswordIdentityProvider', 'attributes': {'id': ['dn'], 'email': ['mail'], 'name': ['cn'], 'preferredUsername': ['uid']}, 'bindDN': 'uid=system,cn=sysaccounts,cn=etc,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com', 'bindPassword': 'bindingpassword', 'ca': '/etc/origin/master/ipa-ca.crt', 'insecure': 'false', 'url': 'ldap://idm.internal.aws.testdrive.openshift.com/cn=users,cn=accounts,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com?uid?sub?(memberOf=cn=ose-user,cn=groups,cn=accounts,dc=auth,dc=internal,dc=aws,dc=testdrive,dc=openshift,dc=com)'}]
                    os_sdn_network_plugin_name=redhat/openshift-ovs-multitenant
                    openshift_master_default_subdomain=apps.${AWS::AccountId}.${PublicHostedZone}
                    openshift_master_cluster_public_hostname=openshift.${AWS::AccountId}.${PublicHostedZone}
                    openshift_web_console_prefix='support.internal.aws.testdrive.openshift.com:5000/openshift3/ose-'

                    openshift_examples_modify_imagestreams=false
                    openshift_additional_repos=[{'id': 'openshift_packages', 'name': 'OpenShift_Packages', 'baseurl': 'http://master.internal.aws.testdrive.openshift.com/repo', 'enabled': 1, 'gpgcheck': 0}]
                    openshift_docker_insecure_registries=support.internal.aws.testdrive.openshift.com:5000
                    openshift_docker_additional_registries=support.internal.aws.testdrive.openshift.com:5000
                    oreg_url=support.internal.aws.testdrive.openshift.com:5000/openshift3/ose-${!component}:${!version}
                    osm_etcd_image=support.internal.aws.testdrive.openshift.com:5000/rhel7/etcd
                    openshift_cli_image=support.internal.aws.testdrive.openshift.com:5000/openshift3/ose
                    osm_image=support.internal.aws.testdrive.openshift.com:5000/openshift3/ose
                    openshift_release=v3.10.14
                    openshift_image_tag=v3.10.14

                    container_runtime_extra_storage="[{'device': '/dev/xvdc', 'path': '/var/lib/origin/openshift.local.volumes', 'options': 'gquota', 'filesystem': 'xfs', 'format': 'True'}]"
                    openshift_hosted_registry_storage_kind=glusterfs 
                    openshift_hosted_registry_storage_volume_size=5Gi
                    openshift_hosted_registry_selector='node-role.kubernetes.io/infra=true'

                    # special storage configs
                    openshift_storage_glusterfs_version=v3.9
                    openshift_storage_glusterfs_heketi_version=v3.9
                    openshift_storage_glusterfs_block_version=v3.9
                    openshift_storage_glusterfs_s3_version=v3.9
                    openshift_storage_glusterfs_namespace=storage
                    openshift_storage_glusterfs_heketi_admin_key=myS3cr3tpassw0rd
                    openshift_storage_glusterfs_storageclass=true
                    openshift_storage_glusterfs_storageclass_default=true
                    openshift_storage_glusterfs_block_deploy=false
                    openshift_storage_glusterfs_registry_version=v3.9
                    openshift_storage_glusterfs_registry_heketi_version=v3.9
                    openshift_storage_glusterfs_registry_block_version=v3.9
                    openshift_storage_glusterfs_registry_s3_version=v3.9
                    openshift_storage_glusterfs_registry_namespace=infra-storage
                    openshift_storage_glusterfs_registry_heketi_admin_key=myS3cr3tpassw0rd
                    openshift_storage_glusterfs_registry_storageclass=true
                    openshift_storage_glusterfs_registry_block_deploy=true
                    openshift_storage_glusterfs_registry_block_storageclass=true
                    openshift_storage_glusterfs_registry_block_host_vol_create=true
                    openshift_storage_glusterfs_registry_block_host_vol_size=30

                    # metrics configs
                    #openshift_metrics_install_metrics=false
                    openshift_metrics_install_metrics=true
                    openshift_metrics_cassandra_storage_type=dynamic
                    openshift_metrics_cassandra_pvc_size=10Gi
                    openshift_metrics_cassanda_pvc_storage_class_name=glusterfs-registry-block
                    openshift_metrics_hawkular_hostname=metrics.apps.${AWS::AccountId}.${PublicHostedZone}

                    # logging configs
                    #openshift_logging_install_logging=false
                    openshift_logging_install_logging=true
                    openshift_logging_namespace=logging
                    openshift_logging_es_pvc_dynamic=true
                    openshift_logging_es_pvc_size=10Gi
                    openshift_logging_es_pvc_storage_class_name=glusterfs-registry-block
                    openshift_logging_es_memory_limit=2G
                    openshift_logging_kibana_hostname=kibana.apps.${AWS::AccountId}.${PublicHostedZone}
                    openshift_logging_public_master_url=https://kibana.apps.${AWS::AccountId}.${PublicHostedZone}

                    # prometheus configs (future)
                    openshift_hosted_prometheus_deploy=true

                    [etcd]
                    master.internal.${PublicHostedZone}

                    [masters]
                    master.internal.${PublicHostedZone}

                    [nodes]
                    master.internal.${PublicHostedZone} openshift_hostname=master.internal.${PublicHostedZone} openshift_public_hostname=master.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-master'
                    infra.internal.${PublicHostedZone} openshift_hostname=infra.internal.${PublicHostedZone} openshift_public_hostname=infra.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-infra'
                    node01.internal.${PublicHostedZone} openshift_hostname=node01.internal.${PublicHostedZone} openshift_public_hostname=node01.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'
                    node02.internal.${PublicHostedZone} openshift_hostname=node02.internal.${PublicHostedZone} openshift_public_hostname=node02.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'
                    node03.internal.${PublicHostedZone} openshift_hostname=node03.internal.${PublicHostedZone} openshift_public_hostname=node03.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'
                    node04.internal.${PublicHostedZone} openshift_node_group_name='node-config-compute' openshift_hostname=node04.internal.${PublicHostedZone} openshift_public_hostname=node04.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'
                    node05.internal.${PublicHostedZone} openshift_node_group_name='node-config-compute' openshift_hostname=node05.internal.${PublicHostedZone} openshift_public_hostname=node05.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'
                    node06.internal.${PublicHostedZone} openshift_node_group_name='node-config-compute' openshift_hostname=node06.internal.${PublicHostedZone} openshift_public_hostname=node06.${AWS::AccountId}.${PublicHostedZone} openshift_node_group_name='node-config-compute'

                    #scaleup_[new_nodes]

                    [glusterfs]
                    node01.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode1.PrivateIp} glusterfs_zone=1 glusterfs_devices='[ "/dev/xvdd" ]'
                    node02.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode2.PrivateIp} glusterfs_zone=2 glusterfs_devices='[ "/dev/xvdd" ]'
                    node03.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode3.PrivateIp} glusterfs_zone=3 glusterfs_devices='[ "/dev/xvdd" ]'

                    [glusterfs_registry]
                    node04.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode4.PrivateIp} glusterfs_zone=1 glusterfs_devices='[ "/dev/xvdd" ]'
                    node05.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode5.PrivateIp} glusterfs_zone=2 glusterfs_devices='[ "/dev/xvdd" ]'
                    node06.internal.${PublicHostedZone} glusterfs_ip=${WorkerNode6.PrivateIp} glusterfs_zone=3 glusterfs_devices='[ "/dev/xvdd" ]'

                    [glusterfs:vars]
                    ansible_become=true

                    [glusterfs_registry:vars]
                    ansible_become=true

                    [idm]
                    idm.internal.${PublicHostedZone}

                    [idm:vars]
                    ansible_become=true
                  path: /etc/ansible/hosts
                  owner: cloud-user:cloud-user

              mounts:
              - [ /dev/xvdd, /var/lib/etcd, xfs, "defaults" ]
            - { RepoAccount: na-se, RepoBranch: combined-workshop }

  InfraNode1NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  InfraNode1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: InfraInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref InfraNode1NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [infra, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: infra.internal.${PublicHostedZone}

  IdmNode1NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref IdmSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  IdmNode1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: IdmInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref IdmNode1NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [idm, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: idm.internal.${PublicHostedZone}

            runcmd:
            - /usr/local/bin/idm-install > /var/log/idm-install.log
            - reboot

  SupportNodeNetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  SupportNode:
    Type: AWS::EC2::Instance
    DependsOn:
      - InternalRoute53Records
      - Master1
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: SupportInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref SupportNodeNetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [support, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub
            - |
              #cloud-config

              fqdn: support.internal.${PublicHostedZone}

              write_files:
              - content: |
                  WORKSHOPS_URLS="https://raw.githubusercontent.com/${RepoAccount}/na-se-openshift-workshop/${RepoBranch}/labguide/_ocp_admin_testdrive.yaml"
                  CONTENT_URL_PREFIX="https://raw.githubusercontent.com/${RepoAccount}/na-se-openshift-workshop/${RepoBranch}/labguide"
                  KEYNAME="${KeyName}"
                  OCP_ROUTING_SUFFIX="apps.${AWS::AccountId}.${PublicHostedZone}"
                  MASTER_HOSTNAME="master"
                  MASTER_EXTERNAL_FQDN="master.${AWS::AccountId}.${PublicHostedZone}"
                  MASTER_EXTERNAL_IP="${Master1.PublicIp}"
                  MASTER_INTERNAL_FQDN="master.internal.${PublicHostedZone}"
                  INFRA_INTERNAL_FQDN="infra.internal.${PublicHostedZone}"
                  INFRA_INTERNAL_IP="${InfraNode1.PrivateIp}"
                  NODE1_HOSTNAME="node01"
                  NODE1_EXTERNAL_FQDN="node01.${AWS::AccountId}.${PublicHostedZone}"
                  NODE1_INTERNAL_FQDN="node01.internal.${PublicHostedZone}"
                  NODE1_INTERNAL_IP="${WorkerNode1.PrivateIp}"
                  NODE2_HOSTNAME="node02"
                  NODE2_EXTERNAL_FQDN="node02.${AWS::AccountId}.${PublicHostedZone}"
                  NODE2_INTERNAL_FQDN="node02.internal.${PublicHostedZone}"
                  NODE2_INTERNAL_IP="${WorkerNode2.PrivateIp}"
                  NODE3_HOSTNAME="node03"
                  NODE3_EXTERNAL_FQDN="node03.${AWS::AccountId}.${PublicHostedZone}"
                  NODE3_INTERNAL_FQDN="node03.internal.${PublicHostedZone}"
                  NODE3_INTERNAL_IP="${WorkerNode3.PrivateIp}"
                  NODE4_EXTERNAL_FQDN="node04.${AWS::AccountId}.${PublicHostedZone}"
                  NODE4_INTERNAL_FQDN="node04.internal.${PublicHostedZone}"
                  NODE4_INTERNAL_IP="${WorkerNode4.PrivateIp}"
                  NODE5_EXTERNAL_FQDN="node05.${AWS::AccountId}.${PublicHostedZone}"
                  NODE5_INTERNAL_FQDN="node05.internal.${PublicHostedZone}"
                  NODE5_INTERNAL_IP="${WorkerNode5.PrivateIp}"
                  NODE6_EXTERNAL_FQDN="node06.${AWS::AccountId}.${PublicHostedZone}"
                  NODE6_INTERNAL_FQDN="node06.internal.${PublicHostedZone}"
                  NODE6_INTERNAL_IP="${WorkerNode6.PrivateIp}"
                  IDM_INTERNAL_FQDN="idm.internal.${PublicHostedZone}"
                  WEB_CONSOLE_URL= "https://openshift.${AWS::AccountId}.${PublicHostedZone}/console"
                  SSH_CONSOLE_URL="http://ssh.${AWS::AccountId}.${PublicHostedZone}:8080/ssh/host/master.internal.${PublicHostedZone}"
                  API_HEALTH_URL= "https://openshift.${AWS::AccountId}.${PublicHostedZone}/healthz/ready"
                  NODE_BRICK_DEVICE="/dev/xvdd"
                  NODE_BRICK_DEVICE2="/dev/xvde"
                  CNS_NAMESPACE="storage"
                  CNS_INFRA_NAMESPACE: "infra-storage"
                  HEKETI_ADMIN_PW="myS3cr3tpassw0rd"
                  CNS_STORAGECLASS: "glusterfs-storage"
                  CNS_BLOCK_STORAGECLASS: "glusterfs-registry-block"
                  CNS_INFRA_STORAGECLASS: "glusterfs-registry"
                path: /etc/sysconfig/workshopper
                owner: root:root

              runcmd:
              - [ systemctl, daemon-reload ]
              - [ systemctl, enable, workshopper ]
              - [ systemctl, start, workshopper ]
              - [ systemctl, enable, webssh2 ]
              - [ systemctl, start, webssh2 ]
              - [ systemctl, start, docker-distribution ]
              - ansible --become localhost -m file -a "path=/tmp/ansible.log state=touch mode=0777"
              - ansible --become localhost -m lineinfile -a "path=/etc/ansible/ansible.cfg regexp='^log_path' line='log_path = /tmp/ansible.log' state=present"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode1.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode2.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode3.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode4.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode5.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${WorkerNode6.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${InfraNode1.PrivateIp}"
              - ansible localhost -m wait_for -a "port=22 host=${Master1.PrivateIp}"
              - ansible localhost -m wait_for -a "port=80 host=${Master1.PrivateIp}"
              - ansible localhost -m wait_for -a "port=389 host=${IdmNode1.PrivateIp}"
              - ansible master.internal.aws.testdrive.openshift.com, -m wait_for -a "path=/etc/origin/master/ipa-ca.crt timeout=600"
              - ansible localhost -m wait_for -a "port=80 host=localhost"
              - ansible localhost -m wait_for -a "port=5000 host=localhost"
              - ansible all -i master.internal.aws.testdrive.openshift.com, -m fetch -a "src=/etc/ansible/hosts dest=/etc/ansible/hosts flat=yes"
              - "ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml ; /usr/local/bin/cfn-signal.sh $? '${OpenShiftWaitHandle}'"
              - "ansible-playbook /opt/lab/support/pv-resize-post-deploy-config.yml ; /usr/local/bin/cfn-signal.sh $? '${PostDeployWaitHandle}'"
              - ansible master.internal.aws.testdrive.openshift.com, -m raw -a "oc get is ruby -n openshift -o json | jq '(.spec.tags[] | select(.name == \"2.3\").from.name) = \"support.internal.aws.testdrive.openshift.com:5000/rhscl/ruby-23-rhel7:latest\"' | jq '(.spec.tags[] | select(.name == \"2.3\").importPolicy.insecure) = true' | oc replace -f -"
              - ansible master.internal.aws.testdrive.openshift.com, -m raw -a "oc get is postgresql -n openshift -o json | jq '(.spec.tags[] | select(.name == \"9.5\").from.name) = \"support.internal.aws.testdrive.openshift.com:5000/rhscl/postgresql-95-rhel7:latest\"' | jq '(.spec.tags[] | select(.name == \"9.5\").importPolicy.insecure) = true' | oc replace -f -"
            - { RepoAccount: na-se, RepoBranch: combined-workshop }

  WorkerNode1NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode1:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: WorkerInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode1NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node01, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node01.internal.${PublicHostedZone}

  WorkerNode2NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet2
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode2:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: WorkerInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode2NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node02, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node02.internal.${PublicHostedZone}

  WorkerNode3NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet3
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode3:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: WorkerInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode3NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node03, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node03.internal.${PublicHostedZone}

  WorkerNode4NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet1
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode4:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: CNSInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode4NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvde
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node04, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node04.internal.${PublicHostedZone}

  WorkerNode5NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet2
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode5:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: CNSInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode5NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvde
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node05, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node05.internal.${PublicHostedZone}

  WorkerNode6NetworkInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId: !Ref PublicSubnet3
      GroupSet:
        - !Ref NodeSecurityGroup
      SourceDestCheck: 'false'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId

  WorkerNode6:
    Type: AWS::EC2::Instance
    Properties:
      ImageId:
        Fn::FindInMap:
        - AWSRegion2AMI
        - Ref: AWS::Region
        - ami
      InstanceType:
        Ref: CNSInstanceType
      NetworkInterfaces:
        - NetworkInterfaceId: !Ref WorkerNode6NetworkInterface
          DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdb
          Ebs:
            VolumeSize: '20'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdc
          Ebs:
            VolumeSize: '10'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvdd
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
        - DeviceName: /dev/xvde
          Ebs:
            VolumeSize: '50'
            VolumeType: 'gp2'
            DeleteOnTermination: 'true'
      Tags:
      - Key: Application
        Value:
          Ref: AWS::StackId
      - Key: Name
        Value: !Join [ ., [node06, !Ref 'AWS::AccountId', !Ref 'PublicHostedZone' ] ]
      UserData:
        Fn::Base64:
          !Sub |
            #cloud-config

            fqdn: node06.internal.${PublicHostedZone}

Outputs:
   LabGuide:
     Description: "Student Lab Guide"
     Value: !Sub "http://support.${AWS::AccountId}.${PublicHostedZone}/"

   SSHConsole:
     Description: "SSH Remote Console to OpenShift Master"
     Value: !Sub "http://ssh.${AWS::AccountId}.${PublicHostedZone}:8080/ssh/host/master.internal.${PublicHostedZone}"

   SSHUserName:
     Description: "Name of the SSH user to login on the master"
     Value: "cloud-user"

   SSHPassword:
     Description: "SSH Password of the user to login on the master"
     Value: !Ref 'KeyName'

   MasterHost:
     Description: "Fully-qualified domain name of the OpenShift Master node"
     Value: !Sub "master.${AWS::AccountId}.${PublicHostedZone}"
